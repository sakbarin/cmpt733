{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 9: Hypothesis Testing (Part 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In many situations, we cannot get the full population but only a sample. If we derive an interesting result from a sample, how likely can we derive the same result from the entire population? In other words, we want to know whether this result is a true finding or it just happens in the sample by chance. Hypothesis testing aims to answer this fundamental question. \n",
    "\n",
    "\n",
    "**Hypothesis Testing**\n",
    "1. Why A/B testing?  \n",
    "2. What is a permutation test? How to implement it?\n",
    "3. What is p-value? How to avoid p-hacking? \n",
    "4. What is a chi-squared test? How to implement it?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1. A/B Testing\n",
    "> Acknowledgment: Thank [Greg Baker](http://www.cs.sfu.ca/~ggbaker/) for helping me to prepare this task.\n",
    "\n",
    "A very common technique to evaluate changes in a user interface is A/B testing: show some users interface A, some interface B, and then look to see if one performs better than the other.\n",
    "\n",
    "Suppose I started an A/B test on CourSys. Here are the two interfaces that I want to compare with. I want to know whether a good placeholder in the search box can attract more users to use the `search` feature.\n",
    "\n",
    "\n",
    "![](img/ab-testing.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The provided [searchlog.json](searchlog.json) has information about users' usage. The question I was interested in: is the number of searches per user different?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To answer this question, we need to first pick up a **test statistic** to quantify how good an interface is. Here, we choose \"the search_count mean\". \n",
    "\n",
    "Please write the code to compute **the difference of the search_count means between interface A and Interface B.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean of search_count for interface 'A': 0.664\n",
      "mean of search_count for interface 'B': 0.799\n",
      "difference of means: 0.135\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# read input\n",
    "df_log = pd.read_json('searchlog.json', lines=True)\n",
    "\n",
    "# function to computer difference\n",
    "def compute_diff(df, verbose):\n",
    "    df_group = df_log[['search_ui', 'search_count']].groupby('search_ui', as_index=False)\n",
    "    df_mean = df_group.mean()\n",
    "\n",
    "    mean_A = float(df_mean[df_mean['search_ui'] == 'A']['search_count'])\n",
    "    mean_B = float(df_mean[df_mean['search_ui'] == 'B']['search_count'])\n",
    "\n",
    "    if (verbose): \n",
    "        print(\"mean of search_count for interface 'A': %2.3f\" % (mean_A))\n",
    "        print(\"mean of search_count for interface 'B': %2.3f\" % (mean_B))\n",
    "        print(\"difference of means: %2.3f\" % (mean_B - mean_A))\n",
    "\n",
    "    return (mean_B - mean_A)\n",
    "\n",
    "base_diff = compute_diff(df_log, True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we find that the mean value increased by 0.135. Then, we wonder whether this result is just caused by random variation. \n",
    "\n",
    "We define the Null Hypothesis as\n",
    " * The difference in search_count mean between Interface A and Interface B is caused by random variation. \n",
    " \n",
    "Then the next job is to check whether we can reject the null hypothesis or not. If it does, we can adopt the alternative explanation:\n",
    " * The difference in search_count mean  between Interface A and Interface B is caused by the design differences between the two.\n",
    "\n",
    "We compute the p-value of the observed result. If p-value is low (e.g., <0.01), we can reject the null hypothesis, and adopt  the alternative explanation.  \n",
    "\n",
    "Please implement a permutation test (numSamples = 10000) to compute the p-value. Note that you are NOT allowed to use an implementation in an existing library. You have to implement it by yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration#: 9750\n",
      "mean of search_count for interface 'A': 0.739\n",
      "mean of search_count for interface 'B': 0.721\n",
      "difference of means: -0.018\n",
      "\n",
      "\n",
      "p-value: 0.124\n",
      "(0.124 >= 0.01) -> (not significant) alternative hypothesis rejected.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "from IPython.display import clear_output\n",
    "from random import shuffle\n",
    "\n",
    "# variables\n",
    "iterations_count = 10000\n",
    "verbose_count = 250\n",
    "\n",
    "# get an array from search_count column\n",
    "arr_searchcount = df_log['search_count'].to_numpy()\n",
    "\n",
    "# create an empty array to keep differences later\n",
    "arr_diff = np.empty((0,1))\n",
    "\n",
    "for i in range(iterations_count):\n",
    "    \n",
    "    # shuffle search count items\n",
    "    shuffle(arr_searchcount)\n",
    "    \n",
    "    # update search_count column after shuffle\n",
    "    df_log['search_count'] = arr_searchcount\n",
    "    \n",
    "    # print every 500 iteration\n",
    "    verbose = (i % verbose_count == 0)\n",
    "    if (verbose):\n",
    "        clear_output(wait=True)\n",
    "        print('iteration#: %d' % (i))\n",
    "\n",
    "    # compute diff value after shuffling\n",
    "    diff = compute_diff(df_log, verbose)\n",
    "    \n",
    "    # add diff value to array of differences\n",
    "    arr_diff = np.append(arr_diff, diff)\n",
    "\n",
    "# length of items greater than or equal to base diff value [=0.135]\n",
    "count = len(arr_diff[ arr_diff >= base_diff ])\n",
    "\n",
    "# compute p-value\n",
    "p_value = count / iterations_count\n",
    "\n",
    "# print output\n",
    "print('\\n')\n",
    "print('p-value: %2.3f' % (p_value))\n",
    "\n",
    "if (p_value <= 0.01):\n",
    "    print('(%2.3f <= 0.01) -> (significant) alternative hypothesis accepted.' % (p_value))\n",
    "else:\n",
    "    print('(%2.3f >= 0.01) -> (not significant) alternative hypothesis rejected.' % (p_value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we want to use the same dataset to do another A/B testing. We suspect that instructors are the ones who can get more useful information from the search feature, so perhaps non-instructors didn't touch the search feature because it was genuinely not relevant to them.\n",
    "\n",
    "So we decide to repeat the above analysis looking only at instructors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q. If using the same dataset to do this analysis, do you feel like we're p-hacking? If so, what can we do with it? **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A.** <i>Yes. If we want to do some other analysis the same dataset to find something interesting, it will be considered as p-hacking. The solution is to divide the level of significance by a factor (example: alpha/2) to do the analysis.</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2. Chi-squared Test "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are tens of different hypothesis testing methods. It's impossible to cover all of them in one week. Given that this is an important topic in statistics, I highly recommend using your free time to learn some other popular ones such as <a href=\"https://en.wikipedia.org/wiki/Chi-squared_test\">Chi-squared test</a>, <a href=\"https://en.wikipedia.org/wiki/G-test\">G-test</a>, <a href=\"https://en.wikipedia.org/wiki/Student%27s_t-test\">T-test</a>, and <a href=\"https://en.wikipedia.org/wiki/Mann%E2%80%93Whitney_U_test\">Mannâ€“Whitney U test</a>.\n",
    "\n",
    "On the searchlog dataset, there are two categorical columns: `is_instructor` and `search_ui`. In Task D, your job is to first learn how a Chi-Squired test works by yourself and then use it to test whether `is_instructor` and `search_ui` are correlated. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please write code to compute the Chi-squared stat. Note that you are **not** allowed to call an existing function (e.g., stats.chi2, chi2_contingency). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chi-squared value: 0.673174\n",
      "degree of freedom: 1\n"
     ]
    }
   ],
   "source": [
    "# get cross tab for is_instructor and search_ui\n",
    "df_ct = pd.crosstab(df_log['is_instructor'], df_log['search_ui'], margins=True) \\\n",
    "            .rename_axis(None, axis=0) \\\n",
    "            .rename_axis(None, axis=1)\n",
    "\n",
    "# get a matrix of numbers from cross tab for further usage\n",
    "matrix = np.array(df_ct, dtype=float)\n",
    "\n",
    "# get ground total value\n",
    "grand_total = matrix[-1:,-1:]\n",
    "\n",
    "# get total column values\n",
    "col_all = matrix[:-1,-1:]\n",
    "\n",
    "# get total row values\n",
    "row_all = matrix[-1:,:-1]\n",
    "\n",
    "# get observed matrix values [without total]\n",
    "o_matrix = matrix[:-1,:-1]\n",
    "\n",
    "# generate expected matrix\n",
    "e_matrix = (row_all * col_all) / grand_total\n",
    "\n",
    "# compute final matrix\n",
    "f_matrix = e_matrix - o_matrix\n",
    "f_matrix = np.power(f_matrix, 2)\n",
    "f_matrix = f_matrix / e_matrix\n",
    "\n",
    "# compute chi-square and degree of freedom\n",
    "chi_square = np.sum(f_matrix)\n",
    "degree_of_freedom = (f_matrix.shape[0] - 1) * (f_matrix.shape[1] - 1)\n",
    "\n",
    "# print output\n",
    "print(\"chi-squared value: %f\" % (chi_square))\n",
    "print(\"degree of freedom: %d\" % (degree_of_freedom))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please explain how to use Chi-squared test to determine whether `is_instructor` and `search_ui` are correlated. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A.** <br>\n",
    "<i>\n",
    "Ho = is_instructor and search_ui are not correlated.<br>\n",
    "Ha = is_instructor and search_ui are correlated.<br>\n",
    "\n",
    "Regarding a specific level of confidence [=0.05], we need to look up chi-square probabilities table. We find the row which corresponds to the problem degree of freedom [=1] and find the column for level of confidence [=0.05]. This value equals to 3.841 in this sample. <br><br>\n",
    "\n",
    "Since the calculated chi-square value 0.673174 < 3.841 [to the left of 0.05], it turns out  the p-value will be greater than 0.05. It's not significant. So, we will reject the alternative hypothesis.\n",
    "\n",
    "we can conclude that is_instructor and search_ui are not correlated.\n",
    "</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete the code in this notebook, and submit it to the CourSys activity Assignment 7."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
